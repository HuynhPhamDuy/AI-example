{"version":3,"sources":["util.js","App.js","index.js"],"names":["extractFaceAndCrop","_ref","Object","asyncToGenerator","regenerator_default","a","mark","_callee","input","detection","widthHeight","face","canvas","colorTensor","grayscaleTensor","_args","arguments","wrap","_context","prev","next","length","undefined","faceapi","sent","document","createElement","width","height","getContext","drawImage","tf","fromPixels","mean","expandDims","abrupt","toFloat","div","stop","_x","_x2","apply","this","App","state","loading","avg","upload","React","createRef","webcam","preview","labels","tinyFace","smileDetector","getInput","tensor","predict","setState","ctx","current","result","createImageData","i","data","putImageData","inputSize","previewInput","dataSync","start","window","performance","now","results","time","inferenceTime","concat","console","warn","_this2","autoDetect","clearInterval","setInterval","imgFile","files","getCanvas","fillRect","_this3","best","bestIdx","forEach","r","push","react_default","key","className","Math","round","react_webcam_default","videoConstraints","facingMode","ref","onClick","toggleAutoDetect","reduce","el","Component","ReactDOM","render","src_App_0","getElementById"],"mappings":"kZAiBaA,EAAkB,eAAAC,EAAAC,OAAAC,EAAA,EAAAD,CAAAE,EAAAC,EAAAC,KAAG,SAAAC,EAChCC,EACAC,GAFgC,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,EAAAC,UAAA,OAAAZ,EAAAC,EAAAY,KAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,UAGhCV,EAHgCK,EAAAM,OAAA,QAAAC,IAAAP,EAAA,GAAAA,EAAA,GAGlB,GAEVJ,EAAOH,GACPC,EAN4B,CAAAS,EAAAE,KAAA,eAAAF,EAAAE,KAAA,EAOhBG,IAAqBf,EAAO,CAACC,IAPb,OAO9BE,EAP8BO,EAAAM,KAO0B,GAP1B,cAS1BZ,EAASa,SAASC,cAAc,WAC/BC,MAAQjB,EACfE,EAAOgB,OAASlB,EAChBE,EAAOiB,WAAW,MAAMC,UAAUnB,EAAM,EAAG,EAAGD,EAAaA,GACrDG,EAAckB,IAAWC,WAAWpB,GACpCE,EAAkBD,EAAYoB,KAAK,GAAGC,WAAW,GAdvBhB,EAAAiB,OAAA,SAkBzBrB,EACJoB,WAAW,GACXE,UACAC,IAAIN,IAAU,OArBe,yBAAAb,EAAAoB,SAAA/B,MAAH,gBAAAgC,EAAAC,GAAA,OAAAvC,EAAAwC,MAAAC,KAAA1B,YAAA,GC+JhB2B,qNAxKbC,MAAQ,CAAEC,SAAS,EAAMC,IAAK,MAC9BC,OAASC,IAAMC,cACfC,OAASF,IAAMC,cACfE,QAAUH,IAAMC,cAChBG,OAAS,CAAC,QAAS,UAAW,OAAQ,QAAS,MAAO,WAAY,4NAM1C7B,IACK,yBAD3BmB,KAAKW,yBAGsBtB,IACA,mCAD3BW,KAAKY,8BAGgBtD,EAAmB0C,KAAKa,mBAAvCC,SACNd,KAAKY,cAAcG,QAAQD,GAC3Bd,KAAKgB,SAAS,CAAEb,SAAS,4IAMdrC,GAGX,IAFA,IAAMmD,EAAMjB,KAAKS,QAAQS,QAAQ/B,WAAW,MACtCgC,EAASF,EAAIG,gBAAgB,GAAI,IAC9BC,EAAI,EAAGA,EAAIvD,EAAMa,OAAQ0C,GAAK,EACrCF,EAAOG,KAAS,EAAJD,GAAoB,IAAXvD,EAAMuD,GAC3BF,EAAOG,KAAS,EAAJD,EAAQ,GAAgB,IAAXvD,EAAMuD,GAC/BF,EAAOG,KAAS,EAAJD,EAAQ,GAAgB,IAAXvD,EAAMuD,GAC/BF,EAAOG,KAAS,EAAJD,EAAQ,GAAK,IAE3BJ,EAAIM,aAAaJ,EAAQ,EAAG,2EAMhBrD,iGACYe,IACtBf,EACA,IAAIe,IAAgC,CAAE2C,UAAW,mBAF7CzD,2CAKiBT,EAAmBQ,EAAOC,UAAzC+C,SACNd,KAAKyB,aAAaX,EAAOY,YACzB1B,KAAKgB,SAAS,CAAEb,SAAS,IACnBwB,EAAQC,OAAOC,YAAYC,MAC3BC,EAAU/B,KAAKY,cAAcG,QAAQD,GAAQY,WAC7CM,EAAOJ,OAAOC,YAAYC,MAAQH,EACxC3B,KAAKgB,SAAS,CACZb,SAAS,EACT8B,cAAeD,EACf5B,IAAKJ,KAAKE,MAAME,IAAI8B,OAAOF,GAC3BD,oCAGFI,QAAQC,KAAK,kLAOE,IAAAC,EAAArC,KACZA,KAAKE,MAAMoC,YAOdC,cAAcvC,KAAKE,MAAMoC,YACzBtC,KAAKgB,SAAS,CAAEsB,YAAY,KAP5BtC,KAAKgB,SAAS,CACZsB,WAAYE,YAAY,WACtBH,EAAKtB,QAAQsB,EAAKxB,aACjB,kKASD4B,EAAUzC,KAAKK,OAAOa,QAAQwB,MAAM,YACxB7D,IAAsB4D,sJAIxC,IAAI3E,EAAQkC,KAAKQ,OAAOU,QAAQyB,YAChC,IAAK7E,EAAO,CACV,IAAMI,EAASa,SAASC,cAAc,UACtCd,EAAOe,MAAQ,IACff,EAAOgB,OAAS,IAChBhB,EAAOiB,WAAW,MAAMyD,SAAS,EAAG,EAAG,IAAK,KAC5C9E,EAAQI,EAGV,OAAOJ,mCAGA,IAAA+E,EAAA7C,KAIH+B,EAAU,GACd,GAAI/B,KAAKE,MAAM+B,cAAe,CAC5B,IAAIa,EAAO,EACPC,EAAU,EACd/C,KAAKE,MAAM6B,QAAQiB,QAAQ,SAACC,EAAG5B,GACzB4B,EAAIH,IACNA,EAAOG,EACPF,EAAU1B,KAGdrB,KAAKE,MAAM6B,QAAQiB,QAAQ,SAACC,EAAG5B,GAAJ,OACzBU,EAAQmB,KACNC,EAAAxF,EAAAqB,cAAA,MAAIoE,IAAK/B,EAAGgC,UAAWhC,GAAK0B,EAAU,OAAS,IAC5CF,EAAKnC,OAAOW,GADf,KACqBiC,KAAKC,MAAU,IAAJN,GAAa,IAD7C,QAMN,OACEE,EAAAxF,EAAAqB,cAAA,OAAKqE,UAAU,OACbF,EAAAxF,EAAAqB,cAAA,UACEqE,UAAW,cAAgBrD,KAAKE,MAAMC,QAAU,eAAiB,KAEjEgD,EAAAxF,EAAAqB,cAACwE,EAAA7F,EAAD,CAAQ8F,iBA1BW,CACvBC,WAAY,QAyBoCC,IAAK3D,KAAKQ,SACtD2C,EAAAxF,EAAAqB,cAAA,OAAKqE,UAAU,gBACbF,EAAAxF,EAAAqB,cAAA,UACEqE,UAAU,aACVO,QAAS,kBAAMf,EAAK9B,QAAQ8B,EAAKhC,cAFnC,gBAMAsC,EAAAxF,EAAAqB,cAAA,UACEqE,UAAU,aACVO,QAAS,kBAAMf,EAAKgB,qBAEnB7D,KAAKE,MAAMoC,WAAa,QAAU,SAJrC,aAMAa,EAAAxF,EAAAqB,cAAA,OAAKqE,UAAU,aACZrD,KAAKE,MAAM+B,eACVkB,EAAAxF,EAAAqB,cAAA,UACEmE,EAAAxF,EAAAqB,cAAA,UACEmE,EAAAxF,EAAAqB,cAAA,+BAA+B,IAC9BsE,KAAKC,MACHvD,KAAKE,MAAME,IAAI0D,OAAO,SAACb,EAAGc,GAAJ,OAAWd,EAAIc,GAAI,GACxC/D,KAAKE,MAAME,IAAIzB,OACf,KACA,IANN,MASAwE,EAAAxF,EAAAqB,cAAA,UACEmE,EAAAxF,EAAAqB,cAAA,sCAAsC,IACrCsE,KAAKC,MAAiC,IAA3BvD,KAAKE,MAAM+B,eAAuB,IAFhD,MAIAkB,EAAAxF,EAAAqB,cAAA,UACEmE,EAAAxF,EAAAqB,cAAA,0BACAmE,EAAAxF,EAAAqB,cAAA,UAAK+C,MAKboB,EAAAxF,EAAAqB,cAAA,UAAQ2E,IAAK3D,KAAKS,QAASxB,MAAM,KAAKC,OAAO,iBAjKvC8E,cCFlBC,IAASC,OAAOf,EAAAxF,EAAAqB,cAACmF,EAAD,MAASpF,SAASqF,eAAe","file":"static/js/main.2b489c34.chunk.js","sourcesContent":["import * as faceapi from \"face-api.js\";\nimport * as tf from \"@tensorflow/tfjs\";\n\nconst cropImage = img => {\n  const size = Math.min(img.shape[0], img.shape[1]);\n  const centerHeight = img.shape[0] / 2;\n  const beginHeight = centerHeight - size / 2;\n  const centerWidth = img.shape[1] / 2;\n  const beginWidth = centerWidth - size / 2;\n  return img.slice([beginHeight, beginWidth, 0], [size, size, 3]);\n};\n\n/**\n * Extract a face from an image given raw input and a\n * detection.  Resize to a square given widthHeight.\n * Convert to a tensor and normalize.\n */\nexport const extractFaceAndCrop = async (\n  input,\n  detection,\n  widthHeight = 48\n) => {\n  let face = input;\n  if (detection) {\n    face = (await faceapi.extractFaces(input, [detection]))[0];\n  }\n  const canvas = document.createElement(\"canvas\");\n  canvas.width = widthHeight;\n  canvas.height = widthHeight;\n  canvas.getContext(\"2d\").drawImage(face, 0, 0, widthHeight, widthHeight);\n  const colorTensor = tf.browser.fromPixels(canvas);\n  const grayscaleTensor = colorTensor.mean(2).expandDims(2);\n  //TODO: deal with aspect ratio and cropping\n  //const croppedTensor = cropImage(grayscaleTensor);\n  //TODO: don't normalize and show the class\n  return grayscaleTensor\n    .expandDims(0)\n    .toFloat()\n    .div(tf.scalar(255));\n};\n","import React, { Component } from \"react\";\nimport Webcam from \"react-webcam\";\nimport * as faceapi from \"face-api.js\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport { extractFaceAndCrop } from \"./util.js\";\nimport \"./App.css\";\n\nclass App extends Component {\n  state = { loading: true, avg: [] };\n  upload = React.createRef();\n  webcam = React.createRef();\n  preview = React.createRef();\n  labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"];\n\n  /**\n   * Load the face detector and smile models\n   */\n  async componentDidMount() {\n    this.tinyFace = await faceapi.loadTinyFaceDetectorModel(\n      process.env.PUBLIC_URL + \"/models\"\n    );\n    this.smileDetector = await tf.loadLayersModel(\n      process.env.PUBLIC_URL + \"models/model.json\"\n    );\n    const tensor = await extractFaceAndCrop(this.getInput());\n    this.smileDetector.predict(tensor);\n    this.setState({ loading: false });\n  }\n\n  /**\n   * Preview the input given to the model\n   */\n  previewInput(input) {\n    const ctx = this.preview.current.getContext(\"2d\");\n    const result = ctx.createImageData(48, 48);\n    for (var i = 0; i < input.length; i += 1) {\n      result.data[i * 4] = input[i] * 255;\n      result.data[i * 4 + 1] = input[i] * 255;\n      result.data[i * 4 + 2] = input[i] * 255;\n      result.data[i * 4 + 3] = 255;\n    }\n    ctx.putImageData(result, 0, 0);\n  }\n\n  /**\n   * Use the loaded model to make a prediction\n   */\n  async predict(input) {\n    const detection = await faceapi.detectSingleFace(\n      input,\n      new faceapi.TinyFaceDetectorOptions({ inputSize: 256 })\n    );\n    if (detection) {\n      const tensor = await extractFaceAndCrop(input, detection);\n      this.previewInput(tensor.dataSync());\n      this.setState({ loading: true });\n      const start = window.performance.now();\n      const results = this.smileDetector.predict(tensor).dataSync();\n      const time = window.performance.now() - start;\n      this.setState({\n        loading: false,\n        inferenceTime: time,\n        avg: this.state.avg.concat(time),\n        results\n      });\n    } else {\n      console.warn(\"No face found, skipping dection\");\n    }\n  }\n\n  /**\n   * Run inference every 200ms\n   */\n  toggleAutoDetect() {\n    if (!this.state.autoDetect) {\n      this.setState({\n        autoDetect: setInterval(() => {\n          this.predict(this.getInput());\n        }, 200)\n      });\n    } else {\n      clearInterval(this.state.autoDetect);\n      this.setState({ autoDetect: false });\n    }\n  }\n\n  async uploadImage() {\n    const imgFile = this.upload.current.files[0];\n    const img = await faceapi.bufferToImage(imgFile);\n  }\n\n  getInput() {\n    let input = this.webcam.current.getCanvas();\n    if (!input) {\n      const canvas = document.createElement(\"canvas\");\n      canvas.width = 100;\n      canvas.height = 100;\n      canvas.getContext(\"2d\").fillRect(0, 0, 100, 100);\n      input = canvas;\n    }\n    //TODO: handle no webcam\n    return input;\n  }\n\n  render() {\n    const videoConstraints = {\n      facingMode: \"user\"\n    };\n    let results = [];\n    if (this.state.inferenceTime) {\n      let best = 0;\n      let bestIdx = 0;\n      this.state.results.forEach((r, i) => {\n        if (r > best) {\n          best = r;\n          bestIdx = i;\n        }\n      });\n      this.state.results.forEach((r, i) =>\n        results.push(\n          <li key={i} className={i == bestIdx ? \"best\" : \"\"}>\n            {this.labels[i]}: {Math.round(r * 10000) / 100}%\n          </li>\n        )\n      );\n    }\n    return (\n      <div className=\"App\">\n        <header\n          className={\"App-header\" + (this.state.loading ? \" App-loading\" : \"\")}\n        >\n          <Webcam videoConstraints={videoConstraints} ref={this.webcam} />\n          <div className=\"App-controls\">\n            <button\n              className=\"App-detect\"\n              onClick={() => this.predict(this.getInput())}\n            >\n              Predict Once\n            </button>\n            <button\n              className=\"App-detect\"\n              onClick={() => this.toggleAutoDetect()}\n            >\n              {this.state.autoDetect ? \"Stop \" : \"Start \"}Streaming\n            </button>\n            <div className=\"App-stats\">\n              {this.state.inferenceTime && (\n                <ul>\n                  <li>\n                    <strong>Average time:</strong>{\" \"}\n                    {Math.round(\n                      (this.state.avg.reduce((r, el) => r + el, 0) /\n                        this.state.avg.length) *\n                        100\n                    ) / 100}\n                    ms\n                  </li>\n                  <li>\n                    <strong>Last inference time:</strong>{\" \"}\n                    {Math.round(this.state.inferenceTime * 100) / 100}ms\n                  </li>\n                  <li>\n                    <strong>Results:</strong>\n                    <ul>{results}</ul>\n                  </li>\n                </ul>\n              )}\n            </div>\n            <canvas ref={this.preview} width=\"48\" height=\"48\" />\n          </div>\n        </header>\n      </div>\n    );\n  }\n}\n\nexport default App;\n","import React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport \"./index.css\";\nimport App from \"./App\";\n\nReactDOM.render(<App />, document.getElementById(\"root\"));\n"],"sourceRoot":""}